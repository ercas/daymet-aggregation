#!/usr/bin/env python3
#
# Convert files of tmin and tmean and their corresponding quantiles generated by
# stage3_extreme_weather.R into a file of hot and cold waves and singleton
# extreme weather events, where waves are defined as two or more days of
# extreme weather concurrently and a singleton extreme weather event is a day
# of extreme weather not followed or preceded  by another day of extreme
# weather.
#
# The output file will have a unique ID for each wave or singleton extreme
# weather event, the length of the wave or "1" for singleton events, and the
# index of the day in the wave e.g. "1" for the 1st day, "2" for the 2nd day,
# etc.
#
# Contact: Edgar Castro <edgar_castro@g.harvard.edu>

import collections
import csv
import datetime
import gzip
import os
import typing

import tqdm


class ExtremeWaveDetector:

    def __init__(self,
                 id_field: str,
                 extreme_label: str,  # "hot" or "cold"
                 output_fp: typing.TextIO,
                 wave_id_start: int = 0):
        self.id_field = id_field
        self.extreme_label = extreme_label

        self.last_date = datetime.datetime(1, 1, 1)
        self.last_id = None

        self.date_stack = []

        self.wave_id = wave_id_start

        self.csv_writer = csv.DictWriter(
            output_fp,
            fieldnames=[self.id_field] + [
                "year", "month", "day", "extreme", "wave_id", "wave_index",
                "wave_length"
            ]
        )
        if wave_id_start == 0:
            self.csv_writer.writeheader()

    def dump_stack(self):
        self.wave_id += 1
        for (i, date) in enumerate(self.date_stack):
            result = {
                self.id_field: self.last_id,
                "year": date.year,
                "month": date.month,
                "day": date.day,
                "extreme": self.extreme_label,
                "wave_id": self.wave_id,
                "wave_index": i + 1,
                "wave_length": len(self.date_stack)
            }
            self.csv_writer.writerow(result)
        self.date_stack = []

    def push(self, line):
        new_id = line[self.id_field]
        new_date = datetime.datetime(
            int(line["date"][:4]),
            int(line["date"][4:6]),
            int(line["date"][6:8])
        )
        # if the ID changes or there is a gap of more than a day, dump the
        # stack
        if (
                (new_id != self.last_id)
                or ((new_date - self.last_date).days > 1)
        ):
            if len(self.date_stack) > 0:
                self.dump_stack()
            self.date_stack = []

        # grow the stack
        self.date_stack.append(new_date)

        self.last_date = new_date
        self.last_id = new_id


def detect_id_column(path: str) -> str:
    with gzip.open(path, "rt") as input_fp:
        return next(csv.reader(input_fp))[0]


# Return format: result[year][id]
def extract_quantiles(input_path: str,
                      quantile: int) -> dict[str, dict[float]]:
    result = collections.defaultdict(dict)
    quantile_field = "pctile{:02d}".format(quantile)
    with gzip.open(input_path, "rt") as input_fp:
        reader = csv.DictReader(input_fp)
        id_field = reader.fieldnames[0]
        for line in reader:
            result[line["year"]][line[id_field]] = float(line[quantile_field])
    return result


def extract_extremes(tmax_path: str,
                     cold_cutoffs_tmax: dict[str, dict[str, float]],
                     tmin_path: str,
                     hot_cutoffs_tmin: dict[str, dict[str, float]],
                     output_path: str
                     ) -> None:
    temp_path = output_path + ".temp"

    with gzip.open(temp_path, "wt") as output_fp:
        last_wave_id = None

        # Detect cold waves
        with gzip.open(tmax_path, "rt") as input_fp:
            reader = csv.DictReader(input_fp)
            id_field = reader.fieldnames[0]

            cold_days = [
                line
                for line in tqdm.tqdm(reader, desc="Extracting extreme cold days")
                if float(line["value"]) < cold_cutoffs_tmax[line["date"][:4]].get(line[id_field], -1e100)
            ]

            tqdm.tqdm.write("Sorting extreme cold days")
            cold_days = sorted(
                cold_days,
                key=lambda line: (line[id_field], line["date"])
            )

            wave_detector = ExtremeWaveDetector(
                id_field=id_field,
                extreme_label="cold",
                output_fp=output_fp,
            )
            for line in tqdm.tqdm(cold_days, desc="Detecting cold waves"):
                wave_detector.push(line)

            # Dump last stack
            wave_detector.dump_stack()

            # Save last wave ID for the heat wave detector
            last_wave_id = wave_detector.wave_id

        # Detect heat waves
        with gzip.open(tmin_path, "rt") as input_fp:
            reader = csv.DictReader(input_fp)
            id_field = reader.fieldnames[0]

            hot_days = [
                line
                for line in tqdm.tqdm(reader, desc="Extracting extreme heat days")
                if float(line["value"]) > hot_cutoffs_tmin[line["date"][:4]].get(line[id_field], -1e100)
            ]

            tqdm.tqdm.write("Sorting extreme heat days")
            hot_days = sorted(
                hot_days,
                key=lambda line: (line[id_field], line["date"])
            )

            wave_detector = ExtremeWaveDetector(
                id_field=id_field,
                extreme_label="hot",
                output_fp=output_fp,
                wave_id_start=last_wave_id
            )
            for line in tqdm.tqdm(hot_days, desc="Detecting cold waves"):
                wave_detector.push(line)

            # Dump last stack
            wave_detector.dump_stack()

    os.rename(temp_path, output_path)


extract_extremes(
    tmax_path="data/mean_tmax.csv.gz",
    cold_cutoffs_tmax=extract_quantiles("data/tmax_quantiles.csv.gz", 1),
    tmin_path="data/mean_tmin.csv.gz",
    hot_cutoffs_tmin=extract_quantiles("data/tmin_quantiles.csv.gz", 99),
    output_path="temp.csv.gz"
)
